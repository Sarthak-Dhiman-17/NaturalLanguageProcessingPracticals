{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1cc0995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download(['stopwords', 'wordnet', 'punkt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea316512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         1\n",
      "     Neutral       0.00      0.00      0.00         2\n",
      "    Positive       0.89      1.00      0.94        24\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.30      0.33      0.31        27\n",
      "weighted avg       0.79      0.89      0.84        27\n",
      "\n",
      "Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Load and clean data\n",
    "df = pd.read_csv('Scraped_Car_Review_ferrari.csv', engine='python')\n",
    "df = df.dropna(subset=['Review', 'Rating']).reset_index(drop=True)\n",
    "\n",
    "# 2. Enhanced label balancing\n",
    "def balanced_label(rating):\n",
    "    if rating >= 4.25: return 'Positive'\n",
    "    elif rating <= 3.0: return 'Negative'\n",
    "    else: return 'Neutral'  # Wider neutral range\n",
    "\n",
    "df['Sentiment'] = df['Rating'].apply(balanced_label)\n",
    "\n",
    "# 3. Advanced text preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return ' '.join([\n",
    "        lemmatizer.lemmatize(word) \n",
    "        for word in tokens \n",
    "        if word.isalpha() \n",
    "        and word not in stop_words\n",
    "        and len(word) > 2\n",
    "    ])\n",
    "\n",
    "df['Clean_Review'] = df['Review'].apply(preprocess)\n",
    "\n",
    "# 4. TF-IDF Vectorization with n-grams\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=1000)\n",
    "X = tfidf.fit_transform(df['Clean_Review'])\n",
    "y = df['Sentiment']\n",
    "\n",
    "# 5. Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 6. Use LinearSVC (better for small datasets)\n",
    "model = LinearSVC(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. Evaluation\n",
    "print(\"Accuracy:\", model.score(X_test, y_test))\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "# 8. Test prediction\n",
    "test_review = \"The transmission failed after 2000 miles. Worst car ever!\"\n",
    "clean_test = preprocess(test_review)\n",
    "print(\"Prediction:\", model.predict(tfidf.transform([clean_test]))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7988160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7092725409836066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.58      0.73      0.65       620\n",
      "     Neutral       0.41      0.30      0.35       854\n",
      "    Positive       0.83      0.85      0.84      2430\n",
      "\n",
      "    accuracy                           0.71      3904\n",
      "   macro avg       0.60      0.63      0.61      3904\n",
      "weighted avg       0.70      0.71      0.70      3904\n",
      "\n",
      "The transmission failed after 2000 miles. Worst car ever!\n",
      "Prediction for test review: Negative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Download NLTK resources (no wordnet needed)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv('Scraped_Car_Review_ford.csv', engine='python')\n",
    "df = df.dropna(subset=['Review', 'Rating']).reset_index(drop=True)\n",
    "\n",
    "# Enhanced label balancing\n",
    "def balanced_label(rating):\n",
    "    if rating >= 4.25: return 'Positive'\n",
    "    elif rating <= 3.0: return 'Negative'\n",
    "    else: return 'Neutral'\n",
    "\n",
    "df['Sentiment'] = df['Rating'].apply(balanced_label)\n",
    "\n",
    "# Text preprocessing with stemming\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return ' '.join([\n",
    "        stemmer.stem(word)\n",
    "        for word in tokens\n",
    "        if word.isalpha()\n",
    "        and word not in stop_words\n",
    "        and len(word) > 2\n",
    "    ])\n",
    "\n",
    "df['Clean_Review'] = df['Review'].apply(preprocess)\n",
    "\n",
    "# TF-IDF Vectorization with n-grams\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=1000)\n",
    "X = tfidf.fit_transform(df['Clean_Review'])\n",
    "y = df['Sentiment']\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Use LinearSVC (better for small datasets)\n",
    "model = LinearSVC(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = model.score(X_test, y_test)\n",
    "report = classification_report(y_test, model.predict(X_test), zero_division=0)\n",
    "\n",
    "# Test prediction\n",
    "test_review = \"The transmission failed after 2000 miles. Worst car ever!\"\n",
    "#test_review = \"Car gained 200 miles per hour speed in 50 seconds! what a great feeling\"\n",
    "clean_test = preprocess(test_review)\n",
    "prediction = model.predict(tfidf.transform([clean_test]))\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n",
    "print(test_review)\n",
    "print(\"Prediction for test review:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11eb406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (50000, 2)\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "Preprocessing text data...\n",
      "Extracting features...\n",
      "\n",
      "Training and evaluating models...\n",
      "\n",
      "Training Naive Bayes...\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8590\n",
      "Precision: 0.8485\n",
      "Recall: 0.8768\n",
      "F1 Score: 0.8624\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86      4961\n",
      "           1       0.85      0.88      0.86      5039\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8816\n",
      "Precision: 0.8760\n",
      "Recall: 0.8912\n",
      "F1 Score: 0.8835\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      4961\n",
      "           1       0.88      0.89      0.88      5039\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8884\n",
      "Precision: 0.8799\n",
      "Recall: 0.9016\n",
      "F1 Score: 0.8906\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      4961\n",
      "           1       0.88      0.90      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Model Comparison:\n",
      "                     accuracy  precision    recall        f1\n",
      "Naive Bayes            0.8590   0.848473  0.876761  0.862385\n",
      "SVM                    0.8816   0.875951  0.891248  0.883533\n",
      "Logistic Regression    0.8884   0.879915  0.901568  0.890610\n",
      "\n",
      "Predicting sentiment for new reviews:\n",
      "\n",
      "Review: This movie was fantastic! The acting was superb and the plot was engaging.\n",
      "Naive Bayes: Positive\n",
      "SVM: Positive\n",
      "Logistic Regression: Positive\n",
      "\n",
      "Review: Terrible movie. Bad acting, worse script. Complete waste of time.\n",
      "Naive Bayes: Negative\n",
      "SVM: Negative\n",
      "Logistic Regression: Negative\n",
      "\n",
      "Review: The movie had some good moments, but overall it was disappointing.\n",
      "Naive Bayes: Negative\n",
      "SVM: Negative\n",
      "Logistic Regression: Negative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the IMDB dataset\n",
    "# You can download this dataset from: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(df.head())\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stopwords and apply stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the review column\n",
    "print(\"Preprocessing text data...\")\n",
    "df['processed_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Convert sentiment to binary (1 for positive, 0 for negative)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['processed_review']\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "print(\"Extracting features...\")\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': LinearSVC(max_iter=10000),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "print(\"\\nTraining and evaluating models...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    # Print detailed classification report\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compare models\n",
    "print(\"\\nModel Comparison:\")\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(comparison_df)\n",
    "\n",
    "# Function to predict sentiment for new reviews\n",
    "def predict_sentiment(review_text, model_name='SVM'):\n",
    "    # Preprocess the new review\n",
    "    processed_review = preprocess_text(review_text)\n",
    "    # Transform to TF-IDF features\n",
    "    review_tfidf = tfidf.transform([processed_review])\n",
    "    # Predict sentiment\n",
    "    prediction = models[model_name].predict(review_tfidf)[0]\n",
    "    sentiment = 'Positive' if prediction == 1 else 'Negative'\n",
    "    return sentiment\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nPredicting sentiment for new reviews:\")\n",
    "test_reviews = [\n",
    "    \"This movie was fantastic! The acting was superb and the plot was engaging.\",\n",
    "    \"Terrible movie. Bad acting, worse script. Complete waste of time.\",\n",
    "    \"The movie had some good moments, but overall it was disappointing.\"\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    nb_sentiment = predict_sentiment(review, 'Naive Bayes')\n",
    "    svm_sentiment = predict_sentiment(review, 'SVM')\n",
    "    lr_sentiment = predict_sentiment(review, 'Logistic Regression')\n",
    "    \n",
    "    print(f\"\\nReview: {review}\")\n",
    "    print(f\"Naive Bayes: {nb_sentiment}\")\n",
    "    print(f\"SVM: {svm_sentiment}\")\n",
    "    print(f\"Logistic Regression: {lr_sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3f6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
