{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba77ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7a1b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords, movie_reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdae4a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"we've\", 'until', 'ain', 'been', 'would', 'again', 'over', 'are', \"haven't\", 'well', 'couldn', 'an', 'll', 'its', 'having', \"he's\", 'were', 'under', 'what', \"he'd\", 'or', 'own', \"that'll\", 'hers', \"it's\", 'against', 'further', \"isn't\", 'because', 'but', \"i've\", 'weren', \"weren't\", \"mightn't\", \"wasn't\", 'd', 'yourself', 'after', \"couldn't\", 'does', 'on', 'in', 'story', 'where', 'itself', 'any', 'ours', 'than', 'to', 'down', 'get', 'has', 'make', 'even', 'aren', \"hadn't\", 'if', 'it', 'through', \"didn't\", 'don', 'y', 'as', 'wouldn', 'one', \"she'd\", 'some', 'haven', 'characters', \"aren't\", 'shan', 'and', 'did', \"i'm\", 'up', 'few', 'he', 'off', \"we'll\", 'with', 'hadn', 'my', \"i'll\", \"we'd\", 'little', 'you', 'more', 'whom', 'below', 'the', \"they'd\", 'me', 'really', 'once', \"needn't\", 'm', 'this', 'their', 'yourselves', 'before', 'character', 'film', 'themselves', 'these', 'now', 'such', 'during', 'two', \"mustn't\", 'which', 'about', 'him', 'am', 'shouldn', \"hasn't\", 'just', 'had', 'her', 're', 'same', \"you've\", \"she's\", \"should've\", 'time', 'do', 'nor', 'out', 'theirs', \"doesn't\", 'himself', \"we're\", 'we', 'by', 's', 'no', 'isn', 'there', 'should', 'wasn', \"they'll\", 'why', 'only', 'see', 'them', 'be', 'those', \"i'd\", \"it'd\", 'most', 'is', \"don't\", 'ourselves', 'from', 'myself', \"you'll\", \"it'll\", 'so', 'then', 'hasn', \"they're\", 'that', 'being', 'when', 'while', 'way', 'ma', 't', \"shan't\", 'a', 'too', 'your', 'much', 'films', 'all', 'of', 'needn', 'have', 'life', 'above', 'will', 'won', 'good', 'at', 'very', \"she'll\", 'how', 'for', 'she', 'doing', 'o', 'each', \"you'd\", 'here', 'also', 'both', 'can', 'yours', 'between', 'plot', 'first', 've', 'not', 'doesn', \"he'll\", 'his', 'i', 'didn', \"they've\", \"shouldn't\", \"you're\", 'mightn', 'was', 'other', 'into', 'our', 'mustn', 'they', 'who', \"won't\", 'movie', \"wouldn't\", 'herself', 'like'}\n",
      "                                                   text  label\n",
      "0     plot : two teen couples go to a church party ,...      0\n",
      "1     the happy bastard ' s quick movie review damn ...      0\n",
      "2     it is movies like these that make a jaded movi...      0\n",
      "3     \" quest for camelot \" is warner bros . ' first...      0\n",
      "4     synopsis : a mentally unstable man undergoing ...      0\n",
      "...                                                 ...    ...\n",
      "1995  wow ! what a movie . it ' s everything a movie...      1\n",
      "1996  richard gere can be a commanding actor , but h...      1\n",
      "1997  glory -- starring matthew broderick , denzel w...      1\n",
      "1998  steven spielberg ' s second epic film on world...      1\n",
      "1999  truman ( \" true - man \" ) burbank is the perfe...      1\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def bcustom_stopwords():\n",
    "    words=[]\n",
    "    for fileid in movie_reviews.fileids():\n",
    "        words.extend(movie_reviews.words(fileid))\n",
    "    freq_dist = nltk.FreqDist(w.lower() for w in words if w.isalpha())\n",
    "    most_common = [word for word, freq in freq_dist.most_common(100)]\n",
    "    base_stopwords = set(stopwords.words('english'))\n",
    "    custom_stopwords = base_stopwords.union(set(most_common))\n",
    "    return custom_stopwords\n",
    "\n",
    "custom_stopwords = bcustom_stopwords()\n",
    "print(custom_stopwords)\n",
    "\n",
    "def get_movie_reviews_data():\n",
    "    docs = []\n",
    "    labels = []\n",
    "    for fileid in movie_reviews.fileids():\n",
    "        label = movie_reviews.categories(fileid)[0]\n",
    "        text = ' '.join(movie_reviews.words(fileid))\n",
    "        docs.append(text)\n",
    "        labels.append(1 if label == 'pos' else 0)\n",
    "    return pd.DataFrame({'text': docs, 'label': labels})\n",
    "\n",
    "movie_df = get_movie_reviews_data()\n",
    "print(movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffd25825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaned Movie Review Texts (first 5) ---\n",
      "                                          clean_text  label\n",
      "0  teen couples go church party drink drive accid...      0\n",
      "1  happy bastard quick review damn bug got head s...      0\n",
      "2  movies jaded viewer thankful invention timex i...      0\n",
      "3  quest camelot warner bros feature length fully...      0\n",
      "4  synopsis mentally unstable man undergoing psyc...      0\n"
     ]
    }
   ],
   "source": [
    "legal_docs = ['The court has decided that the person guilty will not be spared at all and his sentence will atleast be 50 years']\n",
    "\n",
    "def preprocess(text, stopword_list):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in stopword_list]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "movie_df['clean_text'] = movie_df['text'].apply(lambda x: preprocess(x, custom_stopwords))\n",
    "\n",
    "# 4. Print cleaned documents (first 5 for brevity)\n",
    "print(\"\\n--- Cleaned Movie Review Texts (first 5) ---\")\n",
    "print(movie_df[['clean_text', 'label']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cda43e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_accuracy(dataframe, use_stopwords=True):\n",
    "    if use_stopwords:\n",
    "        processed_texts = dataframe['text'].apply(lambda x: preprocess(x, custom_stopwords))\n",
    "    else:\n",
    "        processed_texts = dataframe['text'].apply(lambda x: preprocess(x, set()))\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(processed_texts)\n",
    "    y = dataframe['label']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a289f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with stopword removal: 81.33%\n",
      "Accuracy without stopword removal: 80.17%\n"
     ]
    }
   ],
   "source": [
    "acc_with_stopwords = analyze_sentiment_accuracy(movie_df, use_stopwords=True)\n",
    "acc_without_stopwords = analyze_sentiment_accuracy(movie_df, use_stopwords=False)\n",
    "print(\"Accuracy with stopword removal: {:.2f}%\".format(acc_with_stopwords * 100))\n",
    "print(\"Accuracy without stopword removal: {:.2f}%\".format(acc_without_stopwords * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e4704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
